model:
  base_learning_rate: 1.0e-04
  target: diffusers.model.stable_diffusion_stabilityai.StableDiffusion_CondImagingEmb
  params:
    scale_factor: 0.08333
    prediction_type: v

    unet_config:
      target: diffusers.model.stable_diffusion_stabilityai.UNetModel
      params:
        image_size: 128
        in_channels: 7
        out_channels: 4
        model_channels: 256
        attention_resolutions: [2, 4, 8]
        num_res_blocks: 2
        channel_mult: [1, 2, 2, 4]
        disable_self_attensions: [True, True, True, False]
        disable_middle_self_attn: False
        num_heads: 8
        use_spatial_transformer: True
        transformer_depth: 1
        context_dim: 1024
        legacy: False
        use_linear_in_transformer: True
    
    first_stage_config:
      target: diffusers.model.vae.AutoEncoderKL
      params:
        in_channels: 3
        base_channels: 128
        out_channels: 3
        z_channels: 4
        ch_mult: [1, 2, 4]
        num_res_blocks: 2
        attn_resolutions: []
        dropout: 0.0
    
    cond_stage_config:
      target: diffusers.model.ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder
      params:
        freeze: True
        layer: penultimate